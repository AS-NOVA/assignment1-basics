{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bf159e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing as npt\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import BinaryIO, IO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d2abc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_get_batch(\n",
    "    dataset: npt.NDArray, batch_size: int, context_length: int, device: str\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Given a dataset (a 1D numpy array of integers) and a desired batch size and\n",
    "    context length, sample language modeling input sequences and their corresponding\n",
    "    labels from the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (np.array): 1D numpy array of integer token IDs in the dataset.\n",
    "        batch_size (int): Desired batch size to sample.\n",
    "        context_length (int): Desired context length of each sampled example.\n",
    "        device (str): PyTorch device string (e.g., 'cpu' or 'cuda:0') indicating the device\n",
    "            to place the sampled input sequences and labels on.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of torch.LongTensors of shape (batch_size, context_length). The first tuple item\n",
    "        is the sampled input sequences, and the second tuple item is the corresponding\n",
    "        language modeling labels.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "62a93ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset:npt.NDArray\n",
    "dataset = np.arange(10)\n",
    "data_len = len(dataset)\n",
    "batch_size = 10\n",
    "context_length = 3\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a1a5ee45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 3, 4, 6, 2, 4, 4, 6, 1, 2])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "start_pos = np.random.randint(0,data_len-context_length,batch_size)\n",
    "# 起点下标下限为0，上限为data_len-context_length-1\n",
    "# 最靠后的序列末端下标为data_len-2\n",
    "# 最靠后的序列末端对应的label下标为data_len-1\n",
    "# 正好就是data_len的最后一个下标\n",
    "start_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f7355413",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [dataset[start:start+context_length] for start in start_pos]\n",
    "labels = [dataset[start+1:start+context_length+1] for start in start_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "470bbdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([6, 7, 8]), array([3, 4, 5]), array([4, 5, 6]), array([6, 7, 8]), array([2, 3, 4]), array([4, 5, 6]), array([4, 5, 6]), array([6, 7, 8]), array([1, 2, 3]), array([2, 3, 4])]\n",
      "[array([7, 8, 9]), array([4, 5, 6]), array([5, 6, 7]), array([7, 8, 9]), array([3, 4, 5]), array([5, 6, 7]), array([5, 6, 7]), array([7, 8, 9]), array([2, 3, 4]), array([3, 4, 5])]\n"
     ]
    }
   ],
   "source": [
    "print(seqs)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d79814e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_np = np.stack(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ffc309cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs_tensor = torch.from_numpy(seqs_np).to(device=device)\n",
    "seqs_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b407b35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_get_batch(\n",
    "    dataset: npt.NDArray, batch_size: int, context_length: int, device: str\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    np.random.seed(42)\n",
    "    start_pos = np.random.randint(0,data_len-context_length,batch_size)\n",
    "    # 起点下标下限为0，上限为data_len-context_length-1\n",
    "    # 最靠后的序列末端下标为data_len-2\n",
    "    # 最靠后的序列末端对应的label下标为data_len-1\n",
    "    # 正好就是data_len的最后一个下标\n",
    "    seqs = [dataset[start:start+context_length] for start in start_pos]\n",
    "    labels = [dataset[start+1:start+context_length+1] for start in start_pos]\n",
    "    seqs_np = np.stack(seqs)\n",
    "    seqs_tensor = torch.from_numpy(seqs_np).to(device=device)\n",
    "    labels_np = np.stack(labels)\n",
    "    labels_tensor = torch.from_numpy(labels_np).to(device=device)\n",
    "    return seqs_tensor,labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec9ea59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear()"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cs336_basics.mymodule import Linear\n",
    "from cs336_basics.myoptimizer import MyAdamW\n",
    "test_module = Linear(10,20)\n",
    "test_opt = MyAdamW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_save_checkpoint(\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    iteration: int,\n",
    "    out: str | os.PathLike | BinaryIO | IO[bytes],\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a model, optimizer, and an iteration number, serialize them to disk.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Serialize the state of this model.\n",
    "        optimizer (torch.optim.Optimizer): Serialize the state of this optimizer.\n",
    "        iteration (int): Serialize this value, which represents the number of training iterations\n",
    "            we've completed.\n",
    "        out (str | os.PathLike | BinaryIO | IO[bytes]): Path or file-like object to serialize the model, optimizer, and iteration to.\n",
    "    \"\"\"\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'iteration': iteration\n",
    "    }, out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
