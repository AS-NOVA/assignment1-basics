{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b099c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import einsum, rearrange, reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7884f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Linear(nn.Module) :\n",
    "    def __init__(self, \n",
    "                 in_features:int, \n",
    "                 out_features:int, \n",
    "                 device:torch.device | None = None,\n",
    "                 dtype:torch.dtype | None = None\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        # in out维度记录在模块内部\n",
    "        # tensor位置和类型信息并不属于模块，而是跟着tensor走\n",
    "        # 所以只是传给创建tensor的函数，需要这些信息时直接问tensor而非模块\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        parameter_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "        # 创建一块参数矩阵\n",
    "        # 由于pytorch存储参数时是按行的，每行内容都会连在一起\n",
    "        # 而进行乘法时一定是长为in_features的那一维去乘输入向量\n",
    "        # 所以一定是让in_features作为行的长度，out_features作为行的数量\n",
    "        self.W = nn.Parameter(\n",
    "            torch.empty(\n",
    "                out_features,\n",
    "                in_features,\n",
    "                **parameter_kwargs    # 注意输入的设备和类型信息传到了这里！\n",
    "            ))\n",
    "        \n",
    "        # 初始化：方差为2/(d_in + d_out)，截断处在3个标准差\n",
    "        var = 2.0 / (in_features + out_features)\n",
    "        std = var ** 0.5\n",
    "        nn.init.trunc_normal_(self.W, std=std, a=-3*std, b=3*std)\n",
    "\n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:\n",
    "        # x的形状是 (..., d_in)\n",
    "        # W的形状是 (d_out, d_in)\n",
    "        # 输出形状是 (..., d_out)\n",
    "        # 简单写法：return x @ self.W.T\n",
    "        return einsum(x, self.W, \"... d_in, d_out d_in -> ... d_out\")   #和上面的等价\n",
    "        # 注意：x前面可能有许多维度，但最后一维一定是输入维度d_in\n",
    "        # 而为了方便计算，我们的W是d_out*d_in的\n",
    "        # 所以正常需要转置W才能相乘！这里用einsum来指定怎么乘，可以避免手动转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db73bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "linear = Linear(4, 3)\n",
    "# 测试如何取到模块的所在设备\n",
    "print(linear.W.device)  # cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_embeddings:int, # 词表大小\n",
    "                 embedding_dim:int, # 隐藏空间大小\n",
    "                 device:torch.device | None = None,\n",
    "                 dtype:torch.dtype | None = None\n",
    "                 ) -> None:\n",
    "        super().__init__()\n",
    "        self.embedding_matrix = nn.Parameter(\n",
    "            torch.empty(\n",
    "                num_embeddings,\n",
    "                embedding_dim,\n",
    "                device=device,\n",
    "                dtype=dtype\n",
    "            )\n",
    "        )\n",
    "        nn.init.trunc_normal_(\n",
    "            self.embedding_matrix,\n",
    "            a = -3,\n",
    "            b = 3\n",
    "        )\n",
    "\n",
    "    def forward(self, token_ids: torch.Tensor) -> torch.Tensor:\n",
    "        return self.embedding_matrix[token_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b95ad",
   "metadata": {},
   "source": [
    "Deliverable: Implement RMSNorm as a torch.nn.Module. We recommend the following interface:\n",
    "def __init__(self, d_model: int, eps: float = 1e-5, device=None, dtype=None)\n",
    "Construct the RMSNorm module. This function should accept the following parameters:\n",
    "d_model: int Hidden dimension of the model\n",
    "eps: float = 1e-5 Epsilon value for numerical stability\n",
    "device: torch.device | None = None Device to store the parameters on\n",
    "dtype: torch.dtype | None = None Data type of the parameters\n",
    "\n",
    "def forward(self, x: torch.Tensor) -> torch.Tensor Process an input tensor of shape\n",
    "(batch_size, sequence_length, d_model) and return a tensor of the same shape.\n",
    "Note: Remember to upcast your input to torch.float32 before performing the normalization (and\n",
    "later downcast to the original dtype), as described above.\n",
    "To test your implementation, implement the test adapter at [adapters.run_rmsnorm]. Then, run uv\n",
    "run pytest -k test_rmsnorm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cafb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int, \n",
    "                 eps: float = 1e-5, \n",
    "                 device:torch.device | None = None, \n",
    "                 dtype:torch.dtype | None = None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.eps = eps\n",
    "        parameter_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "        self.gain_parameter = nn.Parameter(\n",
    "            torch.empty(\n",
    "                d_model,\n",
    "                **parameter_kwargs\n",
    "            )\n",
    "        )\n",
    "\n",
    "        nn.init.ones_(self.gain_parameter)\n",
    "\n",
    "        # 其实可以用torch.ones直接初始化，不过这里拆成两部分便于理解\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        in_dtype = x.dtype\n",
    "        x = x.to(torch.float32)\n",
    "        rms = torch.sqrt(reduce(x**2,\"... d -> ... 1\",\"mean\") + self.eps) ** -1 \n",
    "        # 将x的最后一维压缩为一个标量作为分母，但是保留这一维度，便于广播\n",
    "        res = x * rms * self.gain_parameter\n",
    "        # 第一个乘法是因为手动保留了维度所以才能进行的，第二个乘法会自动广播\n",
    "        return res.to(in_dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4e63f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([1, 2, 3])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "n = 3\n",
    "print(type(x))\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee544152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1602)\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "z = torch.sqrt(torch.sum(x**2) / 3)\n",
    "print(z)\n",
    "print(z.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f7e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 10, 18])\n",
      "tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([4,5,6])\n",
    "w = x * y\n",
    "print(w)\n",
    "w = einsum(x,y,\"dim1, dim1 -> dim1\")\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "affe2765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4., 10., 18.],\n",
       "        [16., 25., 36.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([[1,2,3],[4,5,6]]).to(torch.float32)\n",
    "y = torch.tensor([4,5,6]).to(torch.float32)\n",
    "z = einsum(x, y, \"a b, b -> a b\")\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30ec9613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.,  1.],\n",
      "         [ 4.,  5.,  6.,  1.],\n",
      "         [ 1.,  4.,  7., 11.]],\n",
      "\n",
      "        [[ 7.,  8.,  9.,  1.],\n",
      "         [10., 11., 12.,  1.],\n",
      "         [ 2.,  5.,  8., 12.]]])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[1,2,3,1],\n",
    "                   [4,5,6,1],\n",
    "                   [1,4,7,11]],\n",
    "\n",
    "                  [[7,8,9,1],\n",
    "                   [10,11,12,1],\n",
    "                   [2,5,8,12]]])\n",
    "x = x.to(torch.float32)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17468b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2.0000],\n",
      "         [4.4441],\n",
      "         [6.8557]],\n",
      "\n",
      "        [[7.0000],\n",
      "         [9.5786],\n",
      "         [7.7136]]])\n"
     ]
    }
   ],
   "source": [
    "rms = torch.sqrt(reduce(x**2, \"b s d -> b s 1\", \"mean\") + 0.25)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6290fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5000, 1.0000, 1.5000, 0.5000],\n",
      "         [0.9001, 1.1251, 1.3501, 0.2250],\n",
      "         [0.1459, 0.5835, 1.0211, 1.6045]],\n",
      "\n",
      "        [[1.0000, 1.1429, 1.2857, 0.1429],\n",
      "         [1.0440, 1.1484, 1.2528, 0.1044],\n",
      "         [0.2593, 0.6482, 1.0371, 1.5557]]])\n"
     ]
    }
   ],
   "source": [
    "x = x / rms\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9508a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5000, 2.0000, 4.5000, 2.0000],\n",
      "         [0.9001, 2.2502, 4.0503, 0.9001],\n",
      "         [0.1459, 1.1669, 3.0632, 6.4181]],\n",
      "\n",
      "        [[1.0000, 2.2857, 3.8571, 0.5714],\n",
      "         [1.0440, 2.2968, 3.7584, 0.4176],\n",
      "         [0.2593, 1.2964, 3.1114, 6.2228]]])\n",
      "\n",
      "tensor([[[0.5000, 2.0000, 4.5000, 2.0000],\n",
      "         [0.9001, 2.2502, 4.0503, 0.9001],\n",
      "         [0.1459, 1.1669, 3.0632, 6.4181]],\n",
      "\n",
      "        [[1.0000, 2.2857, 3.8571, 0.5714],\n",
      "         [1.0440, 2.2968, 3.7584, 0.4176],\n",
      "         [0.2593, 1.2964, 3.1114, 6.2228]]])\n",
      "\n",
      "tensor([[[0.5000, 2.0000, 4.5000, 2.0000],\n",
      "         [0.9001, 2.2502, 4.0503, 0.9001],\n",
      "         [0.1459, 1.1669, 3.0632, 6.4181]],\n",
      "\n",
      "        [[1.0000, 2.2857, 3.8571, 0.5714],\n",
      "         [1.0440, 2.2968, 3.7584, 0.4176],\n",
      "         [0.2593, 1.2964, 3.1114, 6.2228]]])\n"
     ]
    }
   ],
   "source": [
    "g = torch.tensor([1,2,3,4])\n",
    "z = x * g\n",
    "g1 = rearrange(g, \"d -> 1 1 d\")\n",
    "z1 = x * g1\n",
    "z2 = einsum(x, g, \"b s d, d -> b s d\")\n",
    "print(z)\n",
    "print()\n",
    "print(z1)\n",
    "print()\n",
    "print(z2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "477925fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.0000, 1.0000, 0.6667, 2.0000],\n",
       "         [1.1110, 0.8888, 0.7407, 4.4441],\n",
       "         [6.8557, 1.7139, 0.9794, 0.6232]],\n",
       "\n",
       "        [[1.0000, 0.8750, 0.7778, 7.0000],\n",
       "         [0.9579, 0.8708, 0.7982, 9.5786],\n",
       "         [3.8568, 1.5427, 0.9642, 0.6428]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x ** -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b509859a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "nn.init.ones_(x)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0483350a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1\n",
    "y = x * 8 / 3\n",
    "int(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22b156ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  1],\n",
      "         [ 4,  5,  6,  1],\n",
      "         [ 1,  4,  7, 11]],\n",
      "\n",
      "        [[ 7,  8,  9,  1],\n",
      "         [10, 11, 12,  1],\n",
      "         [ 2,  5,  8, 12]]])\n",
      "tensor([[[ 0.7311,  1.7616,  2.8577,  0.7311],\n",
      "         [ 3.9281,  4.9665,  5.9852,  0.7311],\n",
      "         [ 0.7311,  3.9281,  6.9936, 10.9998]],\n",
      "\n",
      "        [[ 6.9936,  7.9973,  8.9989,  0.7311],\n",
      "         [ 9.9995, 10.9998, 11.9999,  0.7311],\n",
      "         [ 1.7616,  4.9665,  7.9973, 11.9999]]])\n"
     ]
    }
   ],
   "source": [
    "def swish(x:torch.Tensor) -> torch.Tensor:\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "testtensor = torch.tensor([[[1,2,3,1],\n",
    "                   [4,5,6,1],\n",
    "                   [1,4,7,11]],\n",
    "\n",
    "                  [[7,8,9,1],\n",
    "                   [10,11,12,1],\n",
    "                   [2,5,8,12]]])\n",
    "\n",
    "x = testtensor.clone()\n",
    "print(x)\n",
    "print(swish(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ac631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x:torch.Tensor) -> torch.Tensor:\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "class SwiGLUFFN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model:int,\n",
    "                 d_ff:int,\n",
    "                 device:torch.device | None = None,\n",
    "                 dtype:torch.dtype | None = None) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        parameter_kwargs = {\"device\":device,\"dtype\":dtype}\n",
    "\n",
    "        self.linear1 = Linear(d_model,d_ff,**parameter_kwargs)\n",
    "        self.linear2 = Linear(d_ff,d_model,**parameter_kwargs)\n",
    "        self.linear3 = Linear(d_model,d_ff,**parameter_kwargs)\n",
    "    \n",
    "    def forward(self, x:torch.Tensor) -> torch.Tensor:   \n",
    "        activates = swish(self.linear1(x))\n",
    "        gates = self.linear3(x)\n",
    "        return self.linear2(activates * gates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c4ab0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "[[ 1.     0.1    0.01   0.001]\n",
      " [ 2.     0.2    0.02   0.002]\n",
      " [ 3.     0.3    0.03   0.003]\n",
      " [ 4.     0.4    0.04   0.004]\n",
      " [ 5.     0.5    0.05   0.005]\n",
      " [ 6.     0.6    0.06   0.006]\n",
      " [ 7.     0.7    0.07   0.007]\n",
      " [ 8.     0.8    0.08   0.008]\n",
      " [ 9.     0.9    0.09   0.009]\n",
      " [10.     1.     0.1    0.01 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dq = 8\n",
    "halfdq = int(dq/2)\n",
    "maxlen = 10\n",
    "THETA = 10000\n",
    "\n",
    "import math\n",
    "S = math.pow(THETA,-2/dq)\n",
    "print(S)\n",
    "\n",
    "thetas = [[i * math.pow(S,k-1) for k in range(1,halfdq+1)] for i in range(1,maxlen+1)]\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "thetas = np.array(thetas)\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(thetas)\n",
    "plt.imshow(thetas)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e66a99da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "torch.int64 torch.Size([10])\n",
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "itorch = torch.arange(1,maxlen+1)\n",
    "print(itorch)\n",
    "print(itorch.dtype, itorch.shape)\n",
    "rearrange(itorch,\"seq -> seq 1\")\n",
    "print(itorch)\n",
    "print(itorch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c46a5472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 1.0000e-01, 1.0000e-02, 1.0000e-03],\n",
      "        [2.0000e+00, 2.0000e-01, 2.0000e-02, 2.0000e-03],\n",
      "        [3.0000e+00, 3.0000e-01, 3.0000e-02, 3.0000e-03],\n",
      "        [4.0000e+00, 4.0000e-01, 4.0000e-02, 4.0000e-03],\n",
      "        [5.0000e+00, 5.0000e-01, 5.0000e-02, 5.0000e-03],\n",
      "        [6.0000e+00, 6.0000e-01, 6.0000e-02, 6.0000e-03],\n",
      "        [7.0000e+00, 7.0000e-01, 7.0000e-02, 7.0000e-03],\n",
      "        [8.0000e+00, 8.0000e-01, 8.0000e-02, 8.0000e-03],\n",
      "        [9.0000e+00, 9.0000e-01, 9.0000e-02, 9.0000e-03],\n",
      "        [1.0000e+01, 1.0000e+00, 1.0000e-01, 1.0000e-02]])\n"
     ]
    }
   ],
   "source": [
    "ktorch = S ** torch.arange(halfdq)\n",
    "thetastorch = einsum(itorch,ktorch,\"seq, dimq -> seq dimq\")\n",
    "print(thetastorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269d9f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
